# Copyright (C) 2021 Ikomia SAS
# Contact: https://www.ikomia.com
#
# This file is part of the IkomiaStudio software.
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

from ikomia import core, dataprocess
import copy
import random
import torch
import yaml
from infer_transunet.networks.vit_seg_modeling import VisionTransformer as ViT_seg
from ml_collections import ConfigDict
import numpy as np
from torchvision import transforms
import cv2
import os
from torchvision.transforms import InterpolationMode

# Your imports below

# --------------------
# - Class to handle the process parameters
# - Inherits PyCore.CProtocolTaskParam from Ikomia API
# --------------------
class TransunetParam(core.CWorkflowTaskParam):

    def __init__(self):
        core.CWorkflowTaskParam.__init__(self)
        # Place default value initialization here
        self.config_file = ""
        self.model_weight_file = ""

    def set_values(self, param_map):
        # Set parameters values from Ikomia application
        # Parameters values are stored as string and accessible like a python dict
        self.config_file = param_map["config_file"]
        self.model_weight_file = param_map["model_weight_file"]
        pass

    def get_values(self):
        # Send parameters values to Ikomia application
        # Create the specific dict structure (string container)
        param_map = {"config_file": self.config_file,
                    "model_weight_file": self.model_weight_file}
        return param_map


# --------------------
# - Class which implements the process
# - Inherits PyCore.CProtocolTask or derived from Ikomia API
# --------------------
class Transunet(dataprocess.CSemanticSegmentationTask):

    def __init__(self, name, param):
        dataprocess.CSemanticSegmentationTask.__init__(self, name)

        self.model = None
        self.cfg = None
        self.update = False
        self.classes = None

        # Create parameters class
        if param is None:
            self.set_param_object(TransunetParam())
        else:
            self.set_param_object(copy.deepcopy(param))

    def get_progress_steps(self):
        # Function returning the number of progress steps for this process
        # This is handled by the main progress bar of Ikomia application
        return 1

    def run(self):
        # Core function of your process
        # Call begin_task_run for initialization
        self.begin_task_run()

        # we use seed to keep the same color for our masks + boxes + labels (same random each time)
        random.seed(10)
        # Get input :
        img_input = self.get_input(0)
        src_image = img_input.get_image()

        # Get parameters :
        param = self.get_param_object()

        # Config file and model file needed are in the output folder generated by the train plugin
        if (self.cfg is None or param.update) and param.config_file != "":
            with open(param.config_file, 'r') as file:
                config_str = yaml.load(file, Loader=yaml.Loader)
                self.cfg = ConfigDict(config_str)
                self.classes = self.cfg.class_names
                self.set_names(self.classes)

        if (self.model is None or param.update) and self.cfg is not None:
            print("Building model...")
            self.model = ViT_seg(self.cfg, img_size=self.cfg.img_size, num_classes=self.cfg.n_classes)
            print("Model built")

            if torch.cuda.is_available():
                self.model.cuda()

            if os.path.isfile(param.model_weight_file):
                print("Loading weights...")
                self.model.load_state_dict(torch.load(param.model_weight_file))
                print("Weights loaded")
            self.model.eval()

        if self.model is not None and src_image is not None:
            h, w, c = np.shape(src_image)

            downsample_img = transforms.Resize(size=(self.cfg.img_size, self.cfg.img_size),interpolation=InterpolationMode.BICUBIC)
            upsample_pred = transforms.Resize(size=(h,w), interpolation=InterpolationMode.NEAREST)

            with torch.no_grad():
                src_image = torch.tensor([src_image]).permute(0,3,1,2).float()
                if torch.cuda.is_available():
                    src_image = src_image.cuda()

                src_image = downsample_img(src_image)

                if self.cfg.pretrained_path is not None:
                    mean = np.array([123.675, 116.280, 103.530], dtype=np.float)
                    std = np.array([58.395, 57.120, 57.375], dtype=np.float)
                    src_image = Normalize(mean=mean, std=std)(src_image)

                pred = self.model(src_image)
                pred = torch.argmax(torch.softmax(pred, dim=1), dim=1, keepdim=True)
                pred = upsample_pred(pred)
                pred = pred.squeeze()
                pred = pred.cpu().numpy()
                self.set_mask(pred.astype(dtype='uint16'))
            # Set image of input/output (numpy array):

            param.update = False

        # Step progress bar:
        self.emit_step_progress()

        # Call end_task_run to finalize process
        self.end_task_run()


class Normalize(object):
    def __init__(self, mean, std):
        self.mean = mean
        self.std = std

    def __call__(self, image):
        for t, m, s in zip(image, self.mean, self.std):
            t.sub_(m).div_(s)

        return image


# --------------------
# - Factory class to build process object
# - Inherits PyDataProcess.CProcessFactory from Ikomia API
# --------------------
class TransunetFactory(dataprocess.CTaskFactory):

    def __init__(self):
        dataprocess.CTaskFactory.__init__(self)
        # Set process information as string here
        self.info.name = "infer_transunet"
        self.info.short_description = "TransUNet inference for semantic segmentation"
        self.info.authors = "Jieneng Chen, Yongyi Lu, Qihang Yu, Xiangde Luo, Ehsan Adeli, Yan Wang, Le Lu, " \
                            "Alan L. Yuille, Yuyin Zhou"
        # relative path -> as displayed in Ikomia application process tree
        self.info.path = "Plugins/Python/Segmentation"
        self.info.version = "1.2.1"
        self.info.icon_path = "icons/transunet.png"
        self.info.article = "TransUNet: Transformers Make Strong Encoders for Medical Image Segmentation"
        self.info.journal = "not published yet"
        self.info.year = 2021
        self.info.license = "Apache-2.0 License"
        # URL of documentation
        self.info.documentation_link = "https://arxiv.org/abs/2102.04306"
        # Code source repository
        self.info.repository = "https://github.com/Ikomia-hub/infer_transunet"
        self.info.original_repository = "https://github.com/Beckschen/TransUNet"
        # Keywords used for search
        self.info.keywords = "semantic, segmentation, encoder, decoder, Transformers, U-Net"
        self.info.algo_type = core.AlgoType.INFER
        self.info.algo_tasks = "SEMANTIC_SEGMENTATION"

    def create(self, param=None):
        # Create process object
        return Transunet(self.info.name, param)
